{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "from enum import Enum\n",
    "from pydantic import AnyUrl, ValidationError, BaseModel\n",
    "import os\n",
    "from six.moves.urllib.error import HTTPError, URLError\n",
    "import pandas as pd\n",
    "from dlhub_sdk import DLHubClient\n",
    "from mdf_forge import Forge\n",
    "import json\n",
    "\n",
    "class FoundryType(Enum):\n",
    "    tabular=\"tabular\"\n",
    "    files=\"files\"\n",
    "    other=\"other\"\n",
    "    \n",
    "class FoundrySplit(BaseModel):\n",
    "    pass\n",
    "        \n",
    "class FoundryBase(BaseModel):\n",
    "    inputs: List = []\n",
    "    outputs: List = []\n",
    "    input_descriptions: Optional[List] = []\n",
    "    output_descriptions: Optional[List] = []\n",
    "    type: FoundryType = None\n",
    "    uri:Optional[List[AnyUrl]] = []\n",
    "    hash: Optional[str] = []\n",
    "    references: Optional[List[str]] = []\n",
    "    dataframe: Optional[Any] = None\n",
    "        \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class FoundryConfig(BaseModel):\n",
    "    dataframe_file: Optional[str] = \"\" \n",
    "    metadata_file: Optional[str] = \"\"\n",
    "    from_file = True\n",
    "    local_cache_dir = \"\"\n",
    "    \n",
    "class Foundry(BaseModel):\n",
    "    dc: Optional[Dict] = {} #pydantic datacite?\n",
    "    foundry: FoundryBase = {}\n",
    "    config: FoundryConfig = FoundryConfig(dataframe_file=\"foundry_dataframe.json\",\n",
    "                                          metadata_file=\"foundry_metadata.json\",\n",
    "                                          from_file=True,\n",
    "                                          local_cache_dir=\"~/.foundry\")\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class FoundryClient(Foundry):\n",
    "    dlhub_client = DLHubClient()\n",
    "    forge_client = Forge('mdf-test')\n",
    "    \n",
    "    def describe(self):\n",
    "        print(\"DC:{}\".format(self.dc))\n",
    "        print(\"Inputs:{}\".format(self.input_descriptions))\n",
    "        print(\"Outputs:{}\".format(self.output_descriptions))\n",
    "        print(self.output_descriptions)\n",
    "    \n",
    "    def from_file(self, file=None):\n",
    "        if file is None: file= self.config.metadata_file\n",
    "        with open (\"./{}\".format(file)) as fp:\n",
    "            obj = json.load(fp)\n",
    "            return FoundryClient(**obj)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foundry import Foundry\n",
    "f = Foundry(**external_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_data = {\n",
    "    'dc':{'titles':[{\"title\":\"My Dataset Title\"}]},\n",
    "    'dataset':{\n",
    "        'inputs': ['a'],\n",
    "        'outputs': ['c'],\n",
    "        'type': \"tabular\",\n",
    "        'uri':[\"https://s3.amazonaws.com/keras-datasets/boston_housing.npz\"],\n",
    "        'hash':\"asdaasdhahd87264283674\",\n",
    "        'references':[\"@abc\"]\n",
    "    }\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"dc\": {}, \"foundry\": {\"inputs\": [\"configuration\", \"magnetic_moment\", \"stability\", \"delta_e\", \"total_energy\", \"volume_pa\", \"composition\", \"dft_converged\", \"dft_cutoff_energy\", \"dft_exchange_correlation_functional\", \"crystal_structure_number_of_atoms\", \"crystal_structure_space_group\", \"crystal_structure_volume\"], \"outputs\": [\"bandgap\"], \"input_descriptions\": [], \"output_descriptions\": [], \"type\": \"tabular\", \"uri\": [], \"hash\": [], \"references\": []}, \"dataframe\": null, \"config\": {\"dataframe_file\": \"foundry_dataframe.json\", \"metadata_file\": \"foundry_metadata.json\", \"from_file\": true, \"local_cache_dir\": \"~/.foundry\"}}'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.json(exclude={\"dlhub_client\",\"forge_client\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'short_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-067c3ef9121e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfoundry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFoundry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFoundry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s3.amazonaws.com\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/keras-datasets/boston_housing.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git/foundry/foundry/foundry.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, dataframe_file, metadata_file, dc, input_descriptions, output_descriptions, foundry_type, as_file, local_cache_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoundry_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoundry_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_cache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_cache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'short_name' is not defined"
     ]
    }
   ],
   "source": [
    "from foundry import Foundry\n",
    "f=Foundry()\n",
    "f.get_data(\"https\",\"s3.amazonaws.com\",\"/keras-datasets/boston_housing.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muntar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmd5_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhash_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0marchive_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Downloads a file from a URL if it not already in the cache.\n",
       "\n",
       "By default the file at the url `origin` is downloaded to the\n",
       "cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n",
       "and given the filename `fname`. The final location of a file\n",
       "`example.txt` would therefore be `~/.keras/datasets/example.txt`.\n",
       "\n",
       "Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n",
       "Passing a hash will verify the file after download. The command line\n",
       "programs `shasum` and `sha256sum` can compute the hash.\n",
       "\n",
       "# Arguments\n",
       "    fname: Name of the file. If an absolute path `/path/to/file.txt` is\n",
       "        specified the file will be saved at that location.\n",
       "    origin: Original URL of the file.\n",
       "    untar: Deprecated in favor of 'extract'.\n",
       "        boolean, whether the file should be decompressed\n",
       "    md5_hash: Deprecated in favor of 'file_hash'.\n",
       "        md5 hash of the file for verification\n",
       "    file_hash: The expected hash string of the file after download.\n",
       "        The sha256 and md5 hash algorithms are both supported.\n",
       "    cache_subdir: Subdirectory under the Keras cache dir where the file is\n",
       "        saved. If an absolute path `/path/to/folder` is\n",
       "        specified the file will be saved at that location.\n",
       "    hash_algorithm: Select the hash algorithm to verify the file.\n",
       "        options are 'md5', 'sha256', and 'auto'.\n",
       "        The default 'auto' detects the hash algorithm in use.\n",
       "    extract: True tries extracting the file as an Archive, like tar or zip.\n",
       "    archive_format: Archive format to try for extracting the file.\n",
       "        Options are 'auto', 'tar', 'zip', and None.\n",
       "        'tar' includes tar, tar.gz, and tar.bz files.\n",
       "        The default 'auto' is ['tar', 'zip'].\n",
       "        None or an empty list will return no matches found.\n",
       "    cache_dir: Location to store cached files, when None it\n",
       "        defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n",
       "\n",
       "# Returns\n",
       "    Path to the downloaded file\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/rdkit/lib/python3.7/site-packages/keras/utils/data_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.get_data(\"https\",\"s3.amazonaws.com\",\"/keras-datasets/boston_housing.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_data = {\n",
    "    'inputs': ['a'],\n",
    "    'outputs': ['c'],\n",
    "    'type': \"tabular\",\n",
    "    'uri':[\"https://s3.amazonaws.com/keras-datasets/boston_housing.npz\"],\n",
    "    'hash':\"asdaasdhahd87264283674\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    ds = FoundryDataset(**external_data)\n",
    "except ValidationError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FoundryDataset(inputs=['a'], outputs=['c'], type=<FoundryType.tabular: 'tabular'>, uri=[AnyUrl('https://s3.amazonaws.com/keras-datasets/boston_housing.npz', scheme='https', host='s3.amazonaws.com', tld='com', host_type='domain', path='/keras-datasets/boston_housing.npz')], hash='asdaasdhahd87264283674')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"FoundryDataset\",\n",
      "  \"type\": \"object\",\n",
      "  \"properties\": {\n",
      "    \"inputs\": {\n",
      "      \"title\": \"Inputs\",\n",
      "      \"type\": \"array\",\n",
      "      \"items\": {}\n",
      "    },\n",
      "    \"outputs\": {\n",
      "      \"title\": \"Outputs\",\n",
      "      \"type\": \"array\",\n",
      "      \"items\": {}\n",
      "    },\n",
      "    \"type\": {\n",
      "      \"title\": \"Type\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"inputs\",\n",
      "    \"outputs\",\n",
      "    \"type\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(FoundryDataset.schema_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
