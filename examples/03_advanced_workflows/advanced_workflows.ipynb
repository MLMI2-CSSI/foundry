{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MLMI2-CSSI/foundry/blob/main/examples/03_advanced_workflows/advanced_workflows.ipynb)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Foundry Workflows\n",
    "\n",
    "**Time:** 20 minutes  \n",
    "**Prerequisites:** Completed previous examples  \n",
    "**What you'll learn:**\n",
    "- Publishing datasets to Foundry\n",
    "- Exporting to HuggingFace Hub\n",
    "- Using the CLI\n",
    "- MCP server for AI agent integration\n",
    "- Structured error handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Publishing Datasets\n",
    "\n",
    "Share your data with the materials science community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from foundry import Foundry\n\n# HTTPS download is now the default\nf = Foundry()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare Your Metadata\n",
    "\n",
    "Foundry uses DataCite metadata standard. Create a JSON file describing your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"dc\": {\n",
    "        \"titles\": [{\"title\": \"My Band Gap Dataset\"}],\n",
    "        \"creators\": [\n",
    "            {\"creatorName\": \"Smith, John\", \"affiliation\": \"University of Example\"}\n",
    "        ],\n",
    "        \"descriptions\": [{\n",
    "            \"description\": \"Band gap predictions for 1000 materials using DFT calculations.\",\n",
    "            \"descriptionType\": \"Abstract\"\n",
    "        }],\n",
    "        \"publicationYear\": 2024,\n",
    "        \"publisher\": \"Foundry\",\n",
    "        \"resourceType\": {\"resourceType\": \"Dataset\", \"resourceTypeGeneral\": \"Dataset\"}\n",
    "    },\n",
    "    \"foundry\": {\n",
    "        \"data_type\": \"tabular\",\n",
    "        \"keys\": [\n",
    "            {\n",
    "                \"key\": [\"composition\"],\n",
    "                \"type\": \"input\",\n",
    "                \"description\": \"Chemical composition formula\"\n",
    "            },\n",
    "            {\n",
    "                \"key\": [\"band_gap\"],\n",
    "                \"type\": \"target\",\n",
    "                \"description\": \"Calculated band gap\",\n",
    "                \"units\": \"eV\"\n",
    "            }\n",
    "        ],\n",
    "        \"splits\": [\n",
    "            {\"label\": \"train\", \"type\": \"train\"},\n",
    "            {\"label\": \"test\", \"type\": \"test\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Metadata structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Publish (requires Globus authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To publish:\n",
    "# 1. Save metadata to foundry.json\n",
    "# 2. Prepare data files in a folder\n",
    "# 3. Run:\n",
    "\n",
    "# result = f.publish(\n",
    "#     metadata,\n",
    "#     data_path=\"./my_data_folder\",\n",
    "#     source_id=\"my_dataset_v1.0\"\n",
    "# )\n",
    "\n",
    "print(\"See foundry.publish() documentation for full publishing workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check publication status\n",
    "# status = f.check_status(\"my_dataset_v1.0\")\n",
    "# print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exporting to HuggingFace Hub\n",
    "\n",
    "Make your Foundry dataset discoverable on HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install HuggingFace dependencies\n",
    "# !pip install foundry-ml[huggingface]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a Foundry dataset to HuggingFace Hub\n",
    "from foundry.integrations.huggingface import push_to_hub\n",
    "\n",
    "# Get a dataset\n",
    "results = f.search(\"band gap\", limit=1)\n",
    "dataset = results.iloc[0].FoundryDataset\n",
    "\n",
    "# Export to HF Hub (requires HF token)\n",
    "# url = push_to_hub(\n",
    "#     dataset,\n",
    "#     repo_id=\"your-username/dataset-name\",\n",
    "#     token=\"hf_YOUR_TOKEN\",  # or set HF_TOKEN env var\n",
    "#     private=False\n",
    "# )\n",
    "# print(f\"Published at: {url}\")\n",
    "\n",
    "print(\"HuggingFace export ready! Set your HF token to publish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Gets Created on HuggingFace\n",
    "\n",
    "The export automatically creates:\n",
    "- **Data files** in Parquet/Arrow format\n",
    "- **Dataset Card (README.md)** with:\n",
    "  - Title, description from DataCite\n",
    "  - **Authors from original creators** (not the person pushing)\n",
    "  - DOI link to original source\n",
    "  - Field descriptions and units\n",
    "  - BibTeX citation\n",
    "  - Usage examples for both Foundry and HF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the CLI\n",
    "\n",
    "Foundry includes a command-line interface for quick operations.\n",
    "\n",
    "```bash\n",
    "# Search for datasets\n",
    "foundry search \"band gap\"\n",
    "\n",
    "# Get dataset info\n",
    "foundry get 10.18126/abc123\n",
    "\n",
    "# View schema\n",
    "foundry schema 10.18126/abc123\n",
    "\n",
    "# List all datasets\n",
    "foundry catalog --limit 10\n",
    "\n",
    "# JSON output for scripting\n",
    "foundry catalog --json | jq '.[] | .name'\n",
    "\n",
    "# Export to HuggingFace\n",
    "foundry push-to-hf 10.18126/abc123 --repo your-org/dataset-name\n",
    "\n",
    "# Check version\n",
    "foundry version\n",
    "\n",
    "# Get help\n",
    "foundry --help\n",
    "foundry search --help\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CLI from notebook\n",
    "!foundry --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCP Server for AI Agents\n",
    "\n",
    "Foundry includes an MCP (Model Context Protocol) server that allows AI agents like Claude Code to discover and use datasets.\n",
    "\n",
    "### 4.1 Install for Claude Code\n",
    "\n",
    "```bash\n",
    "# Automatically configure Claude Code to use Foundry\n",
    "foundry mcp install\n",
    "```\n",
    "\n",
    "This adds Foundry to your Claude Code configuration, enabling commands like:\n",
    "- \"Find me a materials science dataset for band gap prediction\"\n",
    "- \"What fields are in dataset X?\"\n",
    "- \"Load the training data from dataset Y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Available MCP Tools\n",
    "\n",
    "The MCP server exposes these tools to AI agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from foundry.mcp.server import TOOLS, create_server\n\nprint(\"Available MCP Tools:\")\nprint(\"=\" * 50)\nfor tool in TOOLS:\n    print(f\"\\n{tool['name']}\")\n    print(f\"  {tool['description'][:80]}...\")\n    print(f\"  Parameters: {list(tool['inputSchema']['properties'].keys())}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# View full server configuration\nconfig = create_server()\nprint(f\"Server: {config['name']} v{config['version']}\")\nprint(f\"Tools: {len(config['tools'])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Start MCP Server Manually\n",
    "\n",
    "```bash\n",
    "# Start the server (for custom agent integrations)\n",
    "foundry mcp start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Structured Error Handling\n",
    "\n",
    "Foundry uses structured errors that provide clear context for both humans and AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from foundry.errors import (\n    FoundryError,\n    DatasetNotFoundError,\n    AuthenticationError,\n    DownloadError,\n)\n\n# Example: Handle a not-found error\ntry:\n    raise DatasetNotFoundError(\"fake-doi-12345\")\nexcept DatasetNotFoundError as e:\n    print(f\"Error Code: {e.code}\")\n    print(f\"Message: {e.message}\")\n    print(f\"Details: {e.details}\")\n    print(f\"Recovery Hint: {e.recovery_hint}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Errors can be serialized for API responses\nimport json\n\nerror = DatasetNotFoundError(\"test-query\")\nerror_dict = error.to_dict()\nprint(json.dumps(error_dict, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Types\n",
    "\n",
    "| Error Class | Code | When It's Raised |\n",
    "|------------|------|------------------|\n",
    "| `DatasetNotFoundError` | DATASET_NOT_FOUND | Search/get returns no results |\n",
    "| `AuthenticationError` | AUTH_FAILED | Globus/service auth fails |\n",
    "| `DownloadError` | DOWNLOAD_FAILED | File download fails |\n",
    "| `DataLoadError` | DATA_LOAD_FAILED | Cannot parse data file |\n",
    "| `ValidationError` | VALIDATION_FAILED | Metadata validation error |\n",
    "| `PublishError` | PUBLISH_FAILED | Publishing workflow fails |\n",
    "| `CacheError` | CACHE_ERROR | Local cache issue |\n",
    "| `ConfigurationError` | CONFIG_ERROR | Invalid config setting |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Workflow Example\n",
    "\n",
    "Here's a complete workflow from discovery to model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from foundry import Foundry\nfrom foundry.errors import DatasetNotFoundError\n\ndef train_band_gap_model():\n    \"\"\"Complete workflow: discover -> understand -> load -> train.\"\"\"\n    \n    f = Foundry()\n    \n    # 1. Discover\n    print(\"1. Searching for datasets...\")\n    results = f.search(\"band gap\", limit=5, as_json=True)\n    \n    if not results:\n        raise DatasetNotFoundError(\"band gap\")\n    \n    print(f\"   Found {len(results)} datasets\")\n    \n    # 2. Understand\n    print(\"\\n2. Getting dataset schema...\")\n    dataset = f.list(limit=1).iloc[0].FoundryDataset\n    schema = dataset.get_schema()\n    \n    print(f\"   Dataset: {schema['name']}\")\n    print(f\"   Fields: {[f['name'] for f in schema['fields']]}\")\n    print(f\"   Splits: {[s['name'] for s in schema['splits']]}\")\n    \n    # 3. Load (with schema for context)\n    print(\"\\n3. Loading data...\")\n    result = dataset.get_as_dict(include_schema=True)\n    \n    data = result['data']\n    print(f\"   Loaded splits: {list(data.keys())}\")\n    \n    # 4. Train\n    print(\"\\n4. Ready to train!\")\n    if 'train' in data:\n        X_train, y_train = data['train']\n        print(f\"   Training samples available\")\n    \n    # 5. Cite\n    print(\"\\n5. Citation:\")\n    print(dataset.get_citation())\n    \n    return dataset\n\n# Run it\ntry:\n    ds = train_band_gap_model()\nexcept Exception as e:\n    print(f\"Workflow failed: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### Publishing\n```python\nf.publish(metadata, data_path=\"./data\", source_id=\"my_dataset_v1\")\nf.check_status(\"my_dataset_v1\")\n```\n\n### HuggingFace Export\n```python\nfrom foundry.integrations.huggingface import push_to_hub\npush_to_hub(dataset, \"org/name\", token=\"hf_xxx\")\n```\n\n### CLI\n```bash\nfoundry search \"query\"\nfoundry schema <doi>\nfoundry mcp install\n```\n\n### Error Handling\n```python\nfrom foundry.errors import DatasetNotFoundError\ntry:\n    f.get_dataset(doi)\nexcept DatasetNotFoundError as e:\n    print(e.recovery_hint)\n```\n\n### Configuration\n```python\n# Default: HTTPS download (no Globus needed)\nf = Foundry()\n\n# For cloud environments (Colab, etc.)\nf = Foundry(no_browser=True, no_local_server=True)\n\n# For Globus transfers (large datasets, institutional endpoints)\nf = Foundry(use_globus=True)\n```\n\n---\n\n**You've completed the Foundry tutorial!**\n\n- Documentation: https://github.com/MLMI2-CSSI/foundry\n- Issues: https://github.com/MLMI2-CSSI/foundry/issues"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}